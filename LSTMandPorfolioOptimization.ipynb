{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before starting, the \"FinalDatasets\" folder created by \"DataPrepration\" notebook should be copied to project directory. In case both Notebooks are in the same directory, nothing needs to be done."
      ],
      "metadata": {
        "id": "3VkGvIrypsRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Imports"
      ],
      "metadata": {
        "id": "-1TShnE9GJJp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8n20i6SB0bpQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOCKS = ['BOM500875','BOM532939','BOM524715','BOM532215','BOM532648','BOM532500','BOM500470','BOM500570','BOM500112','BOM532540','BOM500209','BOM500295','BOM532174','BOM500180','BOM500696','BOM500510','BOM500247','BOM500520','BOM532921','BOM532977','BOM500182','BOM507685','BOM500010','BOM532454','BOM500820','BOM500312','BOM532898','BOM532187','BOM533278','BOM532555','BOM570001']"
      ],
      "metadata": {
        "id": "M1VSbrg-oJhO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prepration and LSTM Model creation"
      ],
      "metadata": {
        "id": "RC1X0zsEnaZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for creating input to the model given full dataframe\n",
        "def create_dataset(stock_data_full, lookback=30):\n",
        "  # Initialize empty lists for storing sequences and labels\n",
        "  sequences = []\n",
        "  labels = []\n",
        "\n",
        "  # Loop over the data and create 30-day sequences with corresponding labels\n",
        "  for i in range(len(stock_data_full) - lookback):\n",
        "      # Get the 30-day sequence for this row, including all features\n",
        "      sequence = stock_data_full.iloc[i:i+lookback].values\n",
        "      # Append the sequence to the list\n",
        "      sequences.append(np.float32(sequence))\n",
        "      # Get the label for this sequence, which is the stock price on the next trading day\n",
        "      label = stock_data_full.iloc[i+lookback]['Label']\n",
        "      # Append the label to the list\n",
        "      labels.append(label)\n",
        "\n",
        "  # Convert the sequences and labels to numpy arrays\n",
        "  X = np.array(sequences)\n",
        "  y = np.array(labels)\n",
        "\n",
        "  # Print the shapes of X and y to verify they are the correct dimensions\n",
        "  print(X.shape)  # should be (num_sequences, window_size, num_features)\n",
        "  print(y.shape)  # should be (num_sequences,)\n",
        "\n",
        "  return torch.from_numpy(X), torch.tensor(y)"
      ],
      "metadata": {
        "id": "LMiJ7lFaGrPr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of LSTM model to be used for our traning \n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size[0], batch_first=True, dropout=0.2)\n",
        "        self.lstm2 = nn.LSTM(hidden_size[0], hidden_size[1], batch_first=True, dropout=0.2)\n",
        "        self.lstm3 = nn.LSTM(hidden_size[1], hidden_size[2], batch_first=True, dropout=0.2)\n",
        "        self.linear = nn.Linear(hidden_size[2], output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size[0]).to(device)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size[0]).to(device)\n",
        "        \n",
        "        out, _ = self.lstm1(x, (h0, c0))\n",
        "        out, _ = self.lstm2(out)\n",
        "        out, _ = self.lstm3(out)\n",
        "        out = self.linear(out[:, -1, :])\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "-tXipvWXnzl5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Traning on 1 stock to check correctness"
      ],
      "metadata": {
        "id": "4WbyhPXS7HEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load one stocks dataset into a dataframe\n",
        "df = pd.read_csv('./FinalDatasets/BOM500010Stock.csv')\n",
        "df.set_index('Date', inplace=True)\n",
        "df.sort_index(inplace=True)"
      ],
      "metadata": {
        "id": "gUnXkLMWWt7m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for time series\n",
        "train_size = int(len(df) * 0.80)\n",
        "test_size = len(df) - train_size\n",
        "train, test = df[:train_size], df[train_size:]"
      ],
      "metadata": {
        "id": "KWWxRSewRPn3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DF to Tensors to be used as LSTM Input\n",
        "lookback = 30\n",
        "batch_size =32\n",
        "X_train, y_train = create_dataset(train, lookback=lookback)\n",
        "X_test, y_test = create_dataset(test, lookback=lookback)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "# Create training and testing datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create data loaders for batching the datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "LLkYphN0Jr_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263affa2-5722-468f-9c0f-ce1643a91a78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2566, 30, 26)\n",
            "(2566,)\n",
            "(619, 30, 26)\n",
            "(619,)\n",
            "torch.Size([2566, 30, 26]) torch.Size([2566])\n",
            "torch.Size([619, 30, 26]) torch.Size([619])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.types import Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the model hyperparameters\n",
        "input_size = 26\n",
        "hidden_size = [32, 16, 10]\n",
        "output_size = 1\n",
        "dropout_prob = 0.2\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTMModel(input_size, hidden_size, output_size).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HmGo_2_4ClO",
        "outputId": "d15a90ff-9fa4-4c6a-a63a-63b43b277843"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up hyperparameters\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model and the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "RCM8xBD_JkGp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "# Train the LSTM model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (sequences, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sequences.float()) # cast input tensor to Float\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1)) # cast label tensor to Float\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "jjL7ZqkVWCPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fa5883-e1b2-4578-f301-833f29dc4382"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/20], Loss: 0.6062\n",
            "Epoch [20/20], Loss: 1.1472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for sequences, labels in test_loader:\n",
        "        outputs = model(sequences)\n",
        "        predicted = torch.round(outputs).flatten().int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWTx5jokur3p",
        "outputId": "b207d3dd-a785-4098-8e4a-0a12f0a83f5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 26.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traning pipeline for all 31 stocks"
      ],
      "metadata": {
        "id": "nxZP0VH26qO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traningAccuracies = dict()"
      ],
      "metadata": {
        "id": "gs2EexyP_u6l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainAndTestModelOnStock(stock):\n",
        "  fileName = stock + 'Stock.csv'\n",
        "  df = pd.read_csv('./FinalDatasets/' + fileName)\n",
        "  df.set_index('Date', inplace=True)\n",
        "  df.sort_index(inplace=True)\n",
        "  \n",
        "  # train-test split for time series\n",
        "  train_size = int(len(df) * 0.80)\n",
        "  test_size = len(df) - train_size\n",
        "  train, test = df[:train_size], df[train_size:]\n",
        "\n",
        "  # Convert dataframe to 3-D tensors\n",
        "  lookback = 30\n",
        "  batch_size =32\n",
        "  X_train, y_train = create_dataset(train, lookback=lookback)\n",
        "  X_test, y_test = create_dataset(test, lookback=lookback)\n",
        "  \n",
        "  # Create training and testing datasets\n",
        "  train_dataset = TensorDataset(X_train, y_train)\n",
        "  test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "  # Create data loaders for batching the datasets\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  from torch.types import Device\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  # Define the model hyperparameters\n",
        "  input_size = 26\n",
        "  hidden_size = [32, 16, 10]\n",
        "  output_size = 1\n",
        "  dropout_prob = 0.2\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  # Initialize the model\n",
        "  model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  # Train the LSTM model\n",
        "  num_epochs=20\n",
        "  for epoch in range(num_epochs):\n",
        "      for i, (sequences, labels) in enumerate(train_loader):\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(sequences.float()) # cast input tensor to Float\n",
        "          loss = criterion(outputs, labels.float().unsqueeze(1)) # cast label tensor to Float\n",
        "          loss.backward()\n",
        "          nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "          optimizer.step()\n",
        "\n",
        "      # Print the loss every 10 epochs\n",
        "      if (epoch + 1) % 10 == 0:\n",
        "          print(f\"{stock} Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "  \n",
        "  # Test the Model and save accuracy\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for sequences, labels in test_loader:\n",
        "          outputs = model(sequences)\n",
        "          predicted = torch.round(outputs).flatten().int()\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f\"{stock} Accuracy on test set: {100 * correct / total:.2f}%\")\n",
        "  traningAccuracies[stock] = correct/total"
      ],
      "metadata": {
        "id": "pr-G_49f7Xir"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for stock in STOCKS:\n",
        "  trainAndTestModelOnStock(stock)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I8OAeZD7Scl",
        "outputId": "ea2f7708-4afc-414b-f858-4f5722bdaa0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(708, 30, 26)\n",
            "(708,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500875 Epoch [10/20], Loss: 0.7194\n",
            "BOM500875 Epoch [20/20], Loss: 0.2344\n",
            "BOM500875 Accuracy on test set: 59.18%\n",
            "(2134, 30, 26)\n",
            "(2134,)\n",
            "(512, 30, 26)\n",
            "(512,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532939 Epoch [10/20], Loss: 0.3047\n",
            "BOM532939 Epoch [20/20], Loss: 0.6245\n",
            "BOM532939 Accuracy on test set: 49.02%\n",
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(708, 30, 26)\n",
            "(708,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM524715 Epoch [10/20], Loss: 0.4392\n",
            "BOM524715 Epoch [20/20], Loss: 0.6087\n",
            "BOM524715 Accuracy on test set: 50.99%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532215 Epoch [10/20], Loss: 0.3712\n",
            "BOM532215 Epoch [20/20], Loss: 0.4027\n",
            "BOM532215 Accuracy on test set: 79.27%\n",
            "(2650, 30, 26)\n",
            "(2650,)\n",
            "(641, 30, 26)\n",
            "(641,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532648 Epoch [10/20], Loss: 0.3648\n",
            "BOM532648 Epoch [20/20], Loss: 0.1556\n",
            "BOM532648 Accuracy on test set: 50.23%\n",
            "(2925, 30, 26)\n",
            "(2925,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532500 Epoch [10/20], Loss: 0.4414\n",
            "BOM532500 Epoch [20/20], Loss: 0.6374\n",
            "BOM532500 Accuracy on test set: 36.25%\n",
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(708, 30, 26)\n",
            "(708,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500470 Epoch [10/20], Loss: 0.0648\n",
            "BOM500470 Epoch [20/20], Loss: 0.2876\n",
            "BOM500470 Accuracy on test set: 46.47%\n",
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(708, 30, 26)\n",
            "(708,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500570 Epoch [10/20], Loss: 0.2179\n",
            "BOM500570 Epoch [20/20], Loss: 0.3555\n",
            "BOM500570 Accuracy on test set: 63.70%\n",
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500112 Epoch [10/20], Loss: 0.5293\n",
            "BOM500112 Epoch [20/20], Loss: 0.6293\n",
            "BOM500112 Accuracy on test set: 44.01%\n",
            "(2828, 30, 26)\n",
            "(2828,)\n",
            "(685, 30, 26)\n",
            "(685,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532540 Epoch [10/20], Loss: 0.3378\n",
            "BOM532540 Epoch [20/20], Loss: 0.3044\n",
            "BOM532540 Accuracy on test set: 62.19%\n",
            "(2925, 30, 26)\n",
            "(2925,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500209 Epoch [10/20], Loss: 0.6569\n",
            "BOM500209 Epoch [20/20], Loss: 0.3401\n",
            "BOM500209 Accuracy on test set: 45.56%\n",
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500295 Epoch [10/20], Loss: 0.3217\n",
            "BOM500295 Epoch [20/20], Loss: 0.0595\n",
            "BOM500295 Accuracy on test set: 42.45%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532174 Epoch [10/20], Loss: 0.0560\n",
            "BOM532174 Epoch [20/20], Loss: 0.4904\n",
            "BOM532174 Accuracy on test set: 52.61%\n",
            "(2925, 30, 26)\n",
            "(2925,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500180 Epoch [10/20], Loss: 0.2432\n",
            "BOM500180 Epoch [20/20], Loss: 0.5783\n",
            "BOM500180 Accuracy on test set: 23.55%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500696 Epoch [10/20], Loss: 0.4322\n",
            "BOM500696 Epoch [20/20], Loss: 0.4377\n",
            "BOM500696 Accuracy on test set: 51.34%\n",
            "(2906, 30, 26)\n",
            "(2906,)\n",
            "(705, 30, 26)\n",
            "(705,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500510 Epoch [10/20], Loss: 0.5864\n",
            "BOM500510 Epoch [20/20], Loss: 0.2707\n",
            "BOM500510 Accuracy on test set: 55.89%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500247 Epoch [10/20], Loss: 0.3994\n",
            "BOM500247 Epoch [20/20], Loss: 0.6267\n",
            "BOM500247 Accuracy on test set: 60.51%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(710, 30, 26)\n",
            "(710,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500520 Epoch [10/20], Loss: 0.6483\n",
            "BOM500520 Epoch [20/20], Loss: 0.1048\n",
            "BOM500520 Accuracy on test set: 54.65%\n",
            "(2175, 30, 26)\n",
            "(2175,)\n",
            "(522, 30, 26)\n",
            "(522,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532921 Epoch [10/20], Loss: 0.4138\n",
            "BOM532921 Epoch [20/20], Loss: 0.7351\n",
            "BOM532921 Accuracy on test set: 41.00%\n",
            "(2079, 30, 26)\n",
            "(2079,)\n",
            "(498, 30, 26)\n",
            "(498,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532977 Epoch [10/20], Loss: 0.6895\n",
            "BOM532977 Epoch [20/20], Loss: 0.5558\n",
            "BOM532977 Accuracy on test set: 68.07%\n",
            "(2925, 30, 26)\n",
            "(2925,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500182 Epoch [10/20], Loss: 0.5804\n",
            "BOM500182 Epoch [20/20], Loss: 0.0766\n",
            "BOM500182 Accuracy on test set: 39.21%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM507685 Epoch [10/20], Loss: 0.7717\n",
            "BOM507685 Epoch [20/20], Loss: 0.2991\n",
            "BOM507685 Accuracy on test set: 33.29%\n",
            "(2566, 30, 26)\n",
            "(2566,)\n",
            "(619, 30, 26)\n",
            "(619,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500010 Epoch [10/20], Loss: 0.9698\n",
            "BOM500010 Epoch [20/20], Loss: 1.2235\n",
            "BOM500010 Accuracy on test set: 28.59%\n",
            "(2922, 30, 26)\n",
            "(2922,)\n",
            "(708, 30, 26)\n",
            "(708,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532454 Epoch [10/20], Loss: 0.0859\n",
            "BOM532454 Epoch [20/20], Loss: 0.0489\n",
            "BOM532454 Accuracy on test set: 52.12%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(709, 30, 26)\n",
            "(709,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500820 Epoch [10/20], Loss: 0.0293\n",
            "BOM500820 Epoch [20/20], Loss: 0.2545\n",
            "BOM500820 Accuracy on test set: 62.48%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(710, 30, 26)\n",
            "(710,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM500312 Epoch [10/20], Loss: 0.1916\n",
            "BOM500312 Epoch [20/20], Loss: 0.1708\n",
            "BOM500312 Accuracy on test set: 50.85%\n",
            "(2205, 30, 26)\n",
            "(2205,)\n",
            "(529, 30, 26)\n",
            "(529,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532898 Epoch [10/20], Loss: 0.4311\n",
            "BOM532898 Epoch [20/20], Loss: 0.6547\n",
            "BOM532898 Accuracy on test set: 29.87%\n",
            "(2926, 30, 26)\n",
            "(2926,)\n",
            "(710, 30, 26)\n",
            "(710,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532187 Epoch [10/20], Loss: 0.5828\n",
            "BOM532187 Epoch [20/20], Loss: 0.4495\n",
            "BOM532187 Accuracy on test set: 26.34%\n",
            "(1595, 30, 26)\n",
            "(1595,)\n",
            "(377, 30, 26)\n",
            "(377,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM533278 Epoch [10/20], Loss: 0.2533\n",
            "BOM533278 Epoch [20/20], Loss: 0.2514\n",
            "BOM533278 Accuracy on test set: 31.83%\n",
            "(2789, 30, 26)\n",
            "(2789,)\n",
            "(675, 30, 26)\n",
            "(675,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM532555 Epoch [10/20], Loss: 0.1303\n",
            "BOM532555 Epoch [20/20], Loss: 0.2972\n",
            "BOM532555 Accuracy on test set: 59.70%\n",
            "(1910, 30, 26)\n",
            "(1910,)\n",
            "(456, 30, 26)\n",
            "(456,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOM570001 Epoch [10/20], Loss: 0.1596\n",
            "BOM570001 Epoch [20/20], Loss: 0.3176\n",
            "BOM570001 Accuracy on test set: 35.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Accuracies for each of 31 stock on Testing set is as follows: ')\n",
        "\n",
        "print (\"{:<10} {:<5}\".format('Stock','Accuracy'))\n",
        "for k, v in traningAccuracies.items():\n",
        "        accuracy = v\n",
        "        print (\"{:<8} {:<15}\".format(k, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asCkFpO2CvcL",
        "outputId": "5d401247-71c6-41ab-ddd5-04d47aa50cc5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracies for each of 31 stock on Testing set is as follows: \n",
            "Stock      Accuracy\n",
            "BOM500875 0.5918079096045198\n",
            "BOM532939 0.490234375    \n",
            "BOM524715 0.5098870056497176\n",
            "BOM532215 0.7926657263751763\n",
            "BOM532648 0.5023400936037441\n",
            "BOM532500 0.3624823695345557\n",
            "BOM500470 0.4646892655367232\n",
            "BOM500570 0.6370056497175142\n",
            "BOM500112 0.4400564174894217\n",
            "BOM532540 0.621897810218978\n",
            "BOM500209 0.45557122708039494\n",
            "BOM500295 0.4245416078984485\n",
            "BOM532174 0.5260930888575458\n",
            "BOM500180 0.23554301833568406\n",
            "BOM500696 0.5133991537376587\n",
            "BOM500510 0.5588652482269504\n",
            "BOM500247 0.6050775740479548\n",
            "BOM500520 0.5464788732394367\n",
            "BOM532921 0.4099616858237548\n",
            "BOM532977 0.6807228915662651\n",
            "BOM500182 0.3921015514809591\n",
            "BOM507685 0.3328631875881523\n",
            "BOM500010 0.2859450726978998\n",
            "BOM532454 0.5211864406779662\n",
            "BOM500820 0.6248236953455572\n",
            "BOM500312 0.5084507042253521\n",
            "BOM532898 0.29867674858223064\n",
            "BOM532187 0.2633802816901408\n",
            "BOM533278 0.3183023872679045\n",
            "BOM532555 0.597037037037037\n",
            "BOM570001 0.3530701754385965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Portfolio Optimization"
      ],
      "metadata": {
        "id": "lbnSGxvIGOT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE DONE"
      ],
      "metadata": {
        "id": "LsJWNVZNGR31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "NSNYZXjBQAHV",
        "outputId": "bf651b38-4eee-44af-98a4-b6fc7ea0b050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "alabaster==0.7.13\n",
            "albumentations==1.2.1\n",
            "altair==4.2.2\n",
            "anyio==3.6.2\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==21.3.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.2.0\n",
            "arviz==0.15.1\n",
            "astropy==5.2.2\n",
            "astunparse==1.6.3\n",
            "attrs==23.1.0\n",
            "audioread==3.0.0\n",
            "autograd==1.5\n",
            "Babel==2.12.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.11.2\n",
            "bleach==6.0.0\n",
            "blis==0.7.9\n",
            "blosc2==2.0.0\n",
            "bokeh==2.4.3\n",
            "branca==0.6.0\n",
            "build==0.10.0\n",
            "CacheControl==0.12.11\n",
            "cached-property==1.5.2\n",
            "cachetools==5.3.0\n",
            "catalogue==2.0.8\n",
            "certifi==2022.12.7\n",
            "cffi==1.15.1\n",
            "chardet==4.0.0\n",
            "charset-normalizer==2.0.12\n",
            "chex==0.1.7\n",
            "click==8.1.3\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.25.2\n",
            "cmdstanpy==1.1.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "confection==0.0.4\n",
            "cons==0.4.5\n",
            "contextlib2==0.6.0.post1\n",
            "contourpy==1.0.7\n",
            "convertdate==2.4.0\n",
            "cryptography==40.0.2\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.3.0\n",
            "cvxpy==1.3.1\n",
            "cycler==0.11.0\n",
            "cymem==2.0.7\n",
            "Cython==0.29.34\n",
            "dask==2022.12.1\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.1.1\n",
            "dbus-python==1.2.16\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "distributed==2022.12.1\n",
            "dlib==19.24.1\n",
            "dm-tree==0.1.8\n",
            "docutils==0.16\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.7.1\n",
            "earthengine-api==0.1.350\n",
            "easydict==1.10\n",
            "ecos==2.0.12\n",
            "editdistance==0.6.2\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl#sha256=0964370218b7e1672a30ac50d72cdc6b16f7c867496f1d60925691188f4d2510\n",
            "entrypoints==0.4\n",
            "ephem==4.1.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.2.0\n",
            "etuples==0.3.8\n",
            "exceptiongroup==1.1.1\n",
            "fastai==2.7.12\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.16.3\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.1\n",
            "filelock==3.12.0\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.4\n",
            "flatbuffers==23.3.3\n",
            "flax==0.6.9\n",
            "folium==0.14.0\n",
            "fonttools==4.39.3\n",
            "frozendict==2.3.7\n",
            "fsspec==2023.4.0\n",
            "future==0.18.3\n",
            "gast==0.4.0\n",
            "GDAL==3.3.2\n",
            "gdown==4.6.6\n",
            "gensim==4.3.1\n",
            "geographiclib==2.0\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==2.11.0\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.17.3\n",
            "google-auth-httplib2==0.1.0\n",
            "google-auth-oauthlib==1.0.0\n",
            "google-cloud-bigquery==3.9.0\n",
            "google-cloud-bigquery-storage==2.19.1\n",
            "google-cloud-core==2.3.2\n",
            "google-cloud-datastore==2.15.1\n",
            "google-cloud-firestore==2.11.0\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.1\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=2cffc3ec301c908b14db672a79c4512e64a63a541c42b43c5b9f4a2e184be439\n",
            "google-crc32c==1.5.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.5.0\n",
            "googleapis-common-protos==1.59.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==2.0.2\n",
            "grpcio==1.54.0\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.1.0\n",
            "h5py==3.8.0\n",
            "hijri-converter==2.3.1\n",
            "holidays==0.23\n",
            "holoviews==1.15.4\n",
            "html5lib==1.1\n",
            "httpimport==1.3.0\n",
            "httplib2==0.21.0\n",
            "humanize==4.6.0\n",
            "hyperopt==0.2.7\n",
            "idna==3.4\n",
            "imageio==2.25.1\n",
            "imageio-ffmpeg==0.4.8\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-resources==5.12.0\n",
            "imutils==0.5.4\n",
            "inflect==6.0.4\n",
            "iniconfig==2.0.0\n",
            "intel-openmp==2023.1.0\n",
            "ipykernel==5.5.6\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.4.1\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.8\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.7+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=d8e211ffbd51c1c399b3d78d19c22d8f1d66a0b1b2f96408801069fa1999c17c\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.2.0\n",
            "jsonpickle==3.0.1\n",
            "jsonschema==4.3.3\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.3.0\n",
            "jupyterlab-pygments==0.2.2\n",
            "jupyterlab-widgets==3.0.7\n",
            "kaggle==1.5.13\n",
            "keras==2.12.0\n",
            "kiwisolver==1.4.4\n",
            "korean-lunar-calendar==0.3.1\n",
            "langcodes==3.3.0\n",
            "lazy_loader==0.2\n",
            "libclang==16.0.0\n",
            "librosa==0.10.0.post2\n",
            "lightgbm==3.3.5\n",
            "lit==16.0.3\n",
            "llvmlite==0.39.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.5\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.9.2\n",
            "Markdown==3.4.3\n",
            "markdown-it-py==2.2.0\n",
            "MarkupSafe==2.1.2\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.9\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.8.1\n",
            "mkl==2019.0\n",
            "ml-dtypes==0.1.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==9.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.5\n",
            "multipledispatch==0.6.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.9\n",
            "music21==8.1.0\n",
            "natsort==8.3.1\n",
            "nbclient==0.7.4\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.8.0\n",
            "nest-asyncio==1.5.6\n",
            "networkx==3.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.4.8\n",
            "numba==0.56.4\n",
            "numexpr==2.8.4\n",
            "numpy==1.22.4\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.7.0.72\n",
            "opencv-python==4.7.0.72\n",
            "opencv-python-headless==4.7.0.72\n",
            "openpyxl==3.0.10\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.5\n",
            "orbax-checkpoint==0.2.1\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.1\n",
            "palettable==3.3.3\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.17.9\n",
            "pandocfilters==1.5.0\n",
            "panel==0.14.4\n",
            "param==1.13.0\n",
            "parso==0.8.3\n",
            "partd==1.4.0\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.1\n",
            "patsy==0.5.3\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==8.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==3.3.0\n",
            "plotly==5.13.1\n",
            "plotnine==0.10.1\n",
            "pluggy==1.0.0\n",
            "polars==0.17.3\n",
            "pooch==1.6.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.8\n",
            "prettytable==0.7.2\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.16.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.38\n",
            "prophet==1.1.2\n",
            "proto-plus==1.22.2\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.6\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.5.0\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.6\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.7\n",
            "pydata-google-auth==1.7.0\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyerfa==2.0.0.3\n",
            "pygame==2.3.0\n",
            "Pygments==2.14.0\n",
            "PyGObject==3.36.0\n",
            "pymc==5.1.2\n",
            "PyMeeus==0.5.12\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==3.0.9\n",
            "pyproject_hooks==1.0.0\n",
            "pyrsistent==0.19.3\n",
            "PySocks==1.7.1\n",
            "pytensor==2.10.1\n",
            "pytest==7.2.2\n",
            "python-apt==0.0.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.5.2\n",
            "pytz==2022.7.1\n",
            "pytz-deprecation-shim==0.1.0.post0\n",
            "pyviz-comms==2.2.1\n",
            "PyWavelets==1.4.1\n",
            "PyYAML==6.0\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7\n",
            "qudida==0.0.4\n",
            "regex==2022.10.31\n",
            "requests==2.27.1\n",
            "requests-oauthlib==1.3.1\n",
            "requests-unixsocket==0.2.0\n",
            "requirements-parser==0.5.0\n",
            "rich==13.3.4\n",
            "rpy2==3.5.5\n",
            "rsa==4.9\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.10.1\n",
            "scs==3.2.3\n",
            "seaborn==0.12.2\n",
            "Send2Trash==1.8.0\n",
            "shapely==2.0.1\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.3.0\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.4.1\n",
            "soxr==0.3.5\n",
            "spacy==3.5.2\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.4\n",
            "Sphinx==3.5.4\n",
            "sphinxcontrib-applehelp==1.0.4\n",
            "sphinxcontrib-devhelp==1.0.2\n",
            "sphinxcontrib-htmlhelp==2.0.1\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.3\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "SQLAlchemy==2.0.10\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.6\n",
            "statsmodels==0.13.5\n",
            "sympy==1.11.1\n",
            "tables==3.8.0\n",
            "tabulate==0.8.10\n",
            "tblib==1.7.0\n",
            "tenacity==8.2.2\n",
            "tensorboard==2.12.2\n",
            "tensorboard-data-server==0.7.0\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow==2.12.0\n",
            "tensorflow-datasets==4.9.2\n",
            "tensorflow-estimator==2.12.0\n",
            "tensorflow-gcs-config==2.12.0\n",
            "tensorflow-hub==0.13.0\n",
            "tensorflow-io-gcs-filesystem==0.32.0\n",
            "tensorflow-metadata==1.13.1\n",
            "tensorflow-probability==0.19.0\n",
            "tensorstore==0.1.36\n",
            "termcolor==2.3.0\n",
            "terminado==0.17.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "thinc==8.1.9\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2023.4.12\n",
            "tinycss2==1.2.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=4b690e2b77f21073500c65d8bb9ea9656b8cb4e969f357370bbc992a3b074764\n",
            "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=19c4ef9012324c4fb80ea66934551b7807d97148c28538e2eabafe16ab50e91c\n",
            "torchdata==0.6.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.15.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.15.1%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=9a679fa37a741018c804234693bbac3d487fb3dd55ee73f6b33677b177c8c07a\n",
            "tornado==6.3.1\n",
            "tqdm==4.65.0\n",
            "traitlets==5.7.1\n",
            "triton==2.0.0\n",
            "tweepy==4.13.0\n",
            "typer==0.7.0\n",
            "types-setuptools==67.7.0.2\n",
            "typing_extensions==4.5.0\n",
            "tzdata==2023.3\n",
            "tzlocal==4.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==1.26.15\n",
            "vega-datasets==0.9.0\n",
            "wasabi==1.1.1\n",
            "wcwidth==0.2.6\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.5.1\n",
            "Werkzeug==2.3.0\n",
            "widgetsnbextension==3.6.4\n",
            "wordcloud==1.8.2.2\n",
            "wrapt==1.14.1\n",
            "xarray==2022.12.0\n",
            "xarray-einstats==0.5.1\n",
            "xgboost==1.7.5\n",
            "xlrd==2.0.1\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.18\n",
            "zict==3.0.0\n",
            "zipp==3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLvOaan9QBBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}